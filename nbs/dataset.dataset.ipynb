{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp dataset.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Hasoc.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "df = pd.read_csv(config.DATA_PATH/'fold_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>task1</th>\n",
       "      <th>task2</th>\n",
       "      <th>ID</th>\n",
       "      <th>kfold_task1</th>\n",
       "      <th>kfold_task2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.126953e+18</td>\n",
       "      <td>We need a word for â€˜going somewhere alone,sitt...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>hasoc_2020_en_1503</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.123482e+18</td>\n",
       "      <td>RT @RiverCityLabs: Come and work from our spac...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>hasoc_2020_en_3570</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id  ... kfold_task2\n",
       "0  1.126953e+18  ...           0\n",
       "1  1.123482e+18  ...           0\n",
       "\n",
       "[2 rows x 7 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HOF', 'NOT'], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit_transform(df.task1)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "df['task1_encoded'] = le.transform(df.task1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# TOKENIZER = transformers.BertTokenizer.from_pretrained(\n",
    "#             pretrained_model_name_or_path='bert-base-uncased',\n",
    "#             do_lower_case=True,\n",
    "#             # force_download = True,\n",
    "#         )\n",
    "\n",
    "# MAX_LEN = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BertDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,text, target=None, is_test=False):\n",
    "        self.text, self.target = text, target\n",
    "        self.tokenizer = config.TOKENIZER\n",
    "        self.max_len = config.MAX_LEN\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # sanity check\n",
    "        text = ' '.join(self.text[i].split())\n",
    "\n",
    "        # tokenize using Huggingface tokenizers\n",
    "        out = self.tokenizer.encode_plus(text, None,\n",
    "                                   add_special_tokens=True,\n",
    "                                   max_length = self.max_len,\n",
    "                                   truncation=True)\n",
    "\n",
    "        ids = out['input_ids']\n",
    "        mask = out['attention_mask']\n",
    "        token_type_ids = out['token_type_ids']\n",
    "\n",
    "        padding_length = self.max_len - len(ids)\n",
    "        ids = ids + ([0] * padding_length)\n",
    "        mask = mask + ([0] * padding_length)\n",
    "        token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "\n",
    "        if not self.is_test:\n",
    "            return {\n",
    "                'input_ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'attention_mask': torch.tensor(mask, dtype=torch.long),\n",
    "                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "                'targets': self.onehot(len(np.unique(self.target)), self.target[i])\n",
    "            }\n",
    "        else:\n",
    "            return{\n",
    "                'input_ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'attention_mask': torch.tensor(mask, dtype=torch.long),\n",
    "                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            }\n",
    "\n",
    "    @staticmethod\n",
    "    def onehot(size, target):\n",
    "        vec = torch.zeros(size, dtype=torch.long)\n",
    "        vec[target] = 1.\n",
    "        return vec\n",
    "\n",
    "    def get_labels(self):\n",
    "        return list(self.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "d = BertDataset(df.text.values, df.task1_encoded.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'input_ids': tensor([  101, 23917, 10958,  3676,  3540,  3791,  2115,  2393,  1012,  2023,\n",
       "          2388,  1997, 20662,  8178,  2179,  2041,  2016,  2018,  4456,  2096,\n",
       "          2016,  2001,  1022,  1011,  2706,  6875,  1012,  1529, 16770,  1024,\n",
       "          1013,  1013,  1056,  1012,  2522,  1013,  1057,  3501,  2278,  2575,\n",
       "         12514,  6777,  2080,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'targets': tensor([0, 1]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "d[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = d[0]['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
